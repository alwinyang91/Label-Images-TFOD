{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0. Set up"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Import Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2  # Import opencv\n",
    "import uuid # Import uuid\n",
    "import os # Import Operating System\n",
    "import time # Import time"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Define Category & Setup Folders \n",
    "> &&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&\n",
    "> \n",
    "> **Note:** Before you create new categories and new images, delete collectedimages folder!!!\n",
    "> \n",
    "> &&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "add_category_list = ['ThumbsUp', 'ThumbsDown', 'ThankYou', \"LoveYou\"]\n",
    "add_number_imgs = 10\n",
    "\n",
    "# Path for exported data, numpy arrays\n",
    "IMAGES_PATH = os.path.join('Tensorflow', 'workspace', 'images', 'collectedimages')\n",
    "        \n",
    "for category in add_category_list: \n",
    "    try: \n",
    "        os.makedirs(os.path.join(IMAGES_PATH, category))\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Capture Images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.1 Test Your Webcam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 5\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[39m# Set mediapipe model \u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[39mwhile\u001b[39;00m cap\u001b[39m.\u001b[39misOpened():\n\u001b[1;32m      4\u001b[0m     \u001b[39m# Read feed\u001b[39;00m\n\u001b[0;32m----> 5\u001b[0m     ret, frame \u001b[39m=\u001b[39m cap\u001b[39m.\u001b[39;49mread()\n\u001b[1;32m      7\u001b[0m     cv2\u001b[39m.\u001b[39mputText(frame,\u001b[39m'\u001b[39m\u001b[39mTESTING COLLECTION\u001b[39m\u001b[39m'\u001b[39m, (\u001b[39m120\u001b[39m,\u001b[39m200\u001b[39m), \n\u001b[1;32m      8\u001b[0m                                cv2\u001b[39m.\u001b[39mFONT_HERSHEY_SIMPLEX, \u001b[39m4\u001b[39m, (\u001b[39m0\u001b[39m,\u001b[39m255\u001b[39m, \u001b[39m0\u001b[39m), \u001b[39m4\u001b[39m, cv2\u001b[39m.\u001b[39mLINE_AA)\n\u001b[1;32m      9\u001b[0m     \u001b[39m# Show to screen\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "cap = cv2.VideoCapture(1)\n",
    "# Set mediapipe model q\n",
    "while cap.isOpened():\n",
    "    # Read feed\n",
    "    ret, frame = cap.read()\n",
    "    \n",
    "    cv2.putText(frame,'TESTING COLLECTION', (120,200), \n",
    "                               cv2.FONT_HERSHEY_SIMPLEX, 4, (0,255, 0), 4, cv2.LINE_AA)\n",
    "    # Show to screen\n",
    "    cv2.imshow('OpenCV Feed', frame)\n",
    "    # Break gracefully\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.waitKey(1)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.3 Collect Addational Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for label in add_category_list:\n",
    "    cap = cv2.VideoCapture(1)\n",
    "    print('Collecting images for {}'.format(label))\n",
    "    time.sleep(5)\n",
    "    for imgnum in range(add_number_imgs):\n",
    "        print('Collecting image {}'.format(imgnum))\n",
    "        ret, frame = cap.read()\n",
    "        frame_with_text = frame.copy()  # Create a copy of the original image\n",
    "        if imgnum == 0:\n",
    "            cv2.putText(frame_with_text, 'STARTING COLLECTION', (120,200), \n",
    "                               cv2.FONT_HERSHEY_SIMPLEX, 4, (0,255, 0), 4, cv2.LINE_AA)\n",
    "            cv2.putText(frame_with_text, 'Collecting frames for {} Video Number {}'.format(label, imgnum+1), (60,100), \n",
    "                               cv2.FONT_HERSHEY_SIMPLEX, 2, (0, 0, 255), 2, cv2.LINE_AA)\n",
    "            # Show to screen\n",
    "            cv2.imshow('OpenCV Feed', frame_with_text) \n",
    "            cv2.waitKey(2000)\n",
    "        else:\n",
    "            cv2.putText(frame_with_text, 'Collecting frames for {} Video Number {}'.format(label, imgnum+1), (60,100), \n",
    "                               cv2.FONT_HERSHEY_SIMPLEX, 2, (0, 0, 255), 2, cv2.LINE_AA)\n",
    "            # Show to screen\n",
    "            cv2.imshow('OpenCV Feed', frame_with_text) \n",
    "            \n",
    "        imgname = os.path.join(IMAGES_PATH,label,label+'.'+'{}.jpg'.format(str(uuid.uuid1())))\n",
    "        cv2.imwrite(imgname, frame)  # Save the original image without text\n",
    "        time.sleep(2)\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Image Labelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# labeling_path = os.path.join('labelImg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'labelImg'...\n",
      "remote: Enumerating objects: 2097, done.\u001b[K\n",
      "remote: Counting objects: 100% (7/7), done.\u001b[K\n",
      "remote: Compressing objects: 100% (7/7), done.\u001b[K\n",
      "remote: Total 2097 (delta 0), reused 4 (delta 0), pack-reused 2090\u001b[K\n",
      "Receiving objects: 100% (2097/2097), 237.14 MiB | 9.33 MiB/s, done.\n",
      "Resolving deltas: 100% (1242/1242), done.\n"
     ]
    }
   ],
   "source": [
    "# if not os.path.exists(labeling_path):\n",
    "#     !mkdir {labeling_path}\n",
    "#     !git clone https://github.com/heartexlabs/labelImg {labeling_path}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run `python3 labelImg.py` the app will pop up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Errno 2] No such file or directory: 'labeling_path'\n",
      "/Users/zewen/Documents/AlwinYang91/Sign-Language-Detection\n",
      "python3: can't open file '/Users/zewen/Documents/AlwinYang91/Sign-Language-Detection/labelImg.py': [Errno 2] No such file or directory\n"
     ]
    }
   ],
   "source": [
    "# %cd labeling_path \n",
    "# !python3 labelImg.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Move them into a Training and Testing Partition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OPTIONAL - 7. Compress them for Colab Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_PATH = os.path.join('Tensorflow', 'workspace', 'images', 'train')\n",
    "TEST_PATH = os.path.join('Tensorflow', 'workspace', 'images', 'test')\n",
    "ARCHIVE_PATH = os.path.join('Tensorflow', 'workspace', 'images', 'archive.tar.gz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "!tar -czf {ARCHIVE_PATH} {TRAIN_PATH} {TEST_PATH}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tfod",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
